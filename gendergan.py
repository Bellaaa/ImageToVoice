# -*- coding: utf-8 -*-
"""GenderGAN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19eEGBeCyqVecoYg5O0zjzra8JTUOl7BP
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# % cd '/content/drive/My Drive/785_proj/'

import torch

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
device

!pip install import-ipynb
from torchvision import datasets
import torchvision.transforms  as transforms
import import_ipynb
from tensorboardcolab import TensorBoardColab
tb = TensorBoardColab()

# num_workers = 0
# batch_size = 32
# transform = transforms.Compose(
#     [transforms.Resize((64,64)),
#      transforms.ToTensor(),
#      ])

# train_data = datasets.ImageFolder(root = 'crop_part1', transform=transform)
# train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)

# 1
num_workers = 0
# 2
batch_size = 32
# 3
transform1 = transforms.Compose([
     transforms.Resize((64,64)),
     transforms.RandomGrayscale(p=0.1),
     transforms.ToTensor(),
     ])

transform2 = transforms.Compose([
     transforms.Resize((64,64)),
     transforms.RandomGrayscale(p=0.3),
     transforms.ToTensor(),
     ])
transform3 = transforms.Compose([
     transforms.Resize((64,64)),
     transforms.RandomGrayscale(p=0.5),
     transforms.ToTensor(),
     ])
transform4 = transforms.Compose([
     transforms.Resize((64,64)),
     transforms.RandomGrayscale(p=0.7),
     transforms.ToTensor(),
     ])
# 4
dataset1 = datasets.ImageFolder(root = 'crop_part1', transform=transform1)
dataset2 = datasets.ImageFolder(root = 'crop_part1', transform=transform2)
dataset3 = datasets.ImageFolder(root = 'crop_part1', transform=transform3)
dataset4 = datasets.ImageFolder(root = 'crop_part1', transform=transform4)
# train_data, dev_data = torch.utils.data.random_split(dataset1, [7279, 2500])
train_loader1 = torch.utils.data.DataLoader(dataset1, batch_size=batch_size, shuffle=True, num_workers=num_workers)
train_loader2 = torch.utils.data.DataLoader(dataset2, batch_size=batch_size, shuffle=True, num_workers=num_workers)
train_loader3 = torch.utils.data.DataLoader(dataset3, batch_size=batch_size, shuffle=True, num_workers=num_workers)
train_loader4 = torch.utils.data.DataLoader(dataset4, batch_size=batch_size, shuffle=True, num_workers=num_workers)
# dev_loader = torch.utils.data.DataLoader(dev_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)
train_loader_list = [train_loader1, train_loader2, train_loader3, train_loader4]
num_sample = len(train_loader1)*4

from GeneratorUnet import * 
# from D_G import *
from FaceDiscriminator import *
from GenderDiscriminator import *
from torchvision import models
import torch

G = UNet(3,3).to(device)
# G = torch.load('G.pt').to(device)
D_F = FaceDiscriminator().to(device)
# D_F = torch.load('FD.pt').to(device)
D_G = torch.load('GD.pt').to(device)

"""
define loss
"""
def l2_loss_G(out, input):
    criterion = nn.MSELoss()
    return 10*criterion(out, input)

def l1_loss_G(out, input):
    criterion = nn.L1Loss()
    return 10*criterion(out, input)

def gender_D_loss(out, label):
    batch_size = out.size(0)
    if label == 0:
        labels = torch.zeros(batch_size).to(device)
    if label == 1:
        labels = torch.ones(batch_size).to(device)
    criterion = nn.CrossEntropyLoss()
    return criterion(out, labels.long())

def true_D_loss(out):
    batch_size = out.size(0)
    labels = 0.9 * torch.ones((batch_size ,1)).to(device)
    criterion = nn.BCELoss()
    return criterion(out, labels)

def fake_D_loss(out):
    batch_size = out.size(0)
    labels = torch.zeros((batch_size, 1)).to(device)
    criterion = nn.BCELoss()
    return criterion(out, labels)

import torch.optim as optim

lr = 0.0002
d_optimizer = optim.Adam(D_F.parameters(), lr)
g_optimizer = optim.Adam(G.parameters(), lr)
# g_optimizer = optim.Adam(filter(lambda p: p.requires_grad, G.parameters()), lr=0.0002)
d_scheduler = torch.optim.lr_scheduler.StepLR(d_optimizer, step_size=1, gamma=0.96)
g_scheduler = torch.optim.lr_scheduler.StepLR(g_optimizer, step_size=1, gamma=0.96)

# training
# training hyperparams
# In the following notations, female = 0 male = 1

num_epochs = 20

# keep track of loss and generated, "fake" samples
samples = []
losses = []

print_every = 40

dloss = 0
gloss = 0
dmin = 0.7
gmin = 0.9
# train the network
D_F.train()
G.train()
D_G.train()

for epoch in range(num_epochs):
    for loader_idx, train_loader in enumerate(train_loader_list):
        for batch_idx, (real_images, genders) in enumerate(train_loader):
            batch_size = real_images.size(0)
            real_images, genders = real_images.to(device), genders.to(device)

            # scale the input images, notice when inference
            scaled_images = real_images*2 - 1

            # ============================================
            #            TRAIN THE DISCRIMINATOR
            # ============================================
            if batch_idx % 10 == 0:
                d_optimizer.zero_grad()
              
              # 1. Train with real images

              # Compute the discriminator losses on real images 
                D_real = D_F(scaled_images)
                d_real_loss = true_D_loss(D_real)
              
              # 2. Train with fake images
              
              # Generate fake female images
                fake_images_f = G(scaled_images, 'f')
                fake_images_m = G(scaled_images, 'm')

              # Compute the discriminator losses on fake images        
                D_fake_f = D_F(fake_images_f)
                D_fake_m = D_F(fake_images_m)
                d_fake_f_loss = fake_D_loss(D_fake_f)
                d_fake_m_loss = fake_D_loss(D_fake_m)

              # add up loss and perform backprop
                d_loss = (d_real_loss + d_fake_f_loss + d_fake_m_loss)/3
                dloss += d_loss.item()
                d_loss.backward()
                d_optimizer.step()

            # =========================================
            #            TRAIN THE GENERATOR
            # =========================================
            g_optimizer.zero_grad()
            # 1. Train with l2loss
            # Generate fake female images
            fake_images_f = G(scaled_images, 'f')
            fake_images_m = G(scaled_images, 'm')


            l2loss_f = l2_loss_G(fake_images_f, real_images)   
            l2loss_m = l2_loss_G(fake_images_m, real_images)

            # 2. Train with gender discriminator
            D_G_fake_f = D_G(fake_images_f)
            D_G_fake_m = D_G(fake_images_m)

            gender_loss_f = gender_D_loss(D_G_fake_f, 0)
            gender_loss_m = gender_D_loss(D_G_fake_m, 1)

            # 3. Train with face discriminator
            # using flipped labels?
            D_F_fake_f = D_F(fake_images_f)
            D_F_fake_m = D_F(fake_images_m)

            face_loss_f =  true_D_loss(D_F_fake_f)
            face_loss_m =  true_D_loss(D_F_fake_m)

            # 4.consistency loss
            scaled_fake_f = fake_images_f*2 - 1
            scaled_fake_m = fake_images_f*2 - 1
            fake_cycle_f = G(scaled_fake_f, 'f')
            fake_cycle_m = G(scaled_fake_m, 'm')

            c_loss_f = l2_loss_G(fake_cycle_f, real_images)
            c_loss_m = l2_loss_G(fake_cycle_m, real_images)

            # sum all the loss
            g_loss = ((l2loss_f + l2loss_m + c_loss_f + c_loss_m) + (gender_loss_f + gender_loss_m) + (face_loss_f + face_loss_m))/8
            # g_loss = (l2loss_m + l2loss_f + c_loss_f + c_loss_m)
            # perform backprop
            g_loss.backward()
            gloss += g_loss.item()
            g_optimizer.step()

            # Print some loss stats
            if batch_idx % print_every == print_every-1:
                # print discriminator and generator loss
                print('Epoch [{:5d}/{:5d}] | Batch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f} | gender_loss: {:6.4f} | l2_loss: {:6.4f}'.format(
                        epoch+1, num_epochs, loader_idx*len(train_loader)+batch_idx+1, num_sample, dloss*10/print_every, gloss/print_every, gender_loss_f, l2loss_f))
                # print(gloss)
                if g_loss < gmin:
                    gmin = gloss
                    torch.save(G, 'G.pt')
                if d_loss < dmin:
                    dmin = dloss
                    torch.save(D_F, 'FD.pt')
                dloss = 0
                gloss = 0
            tb.save_value('Train Loss', 'g_loss', epoch*num_sample+loader_idx*len(train_loader)+batch_idx, g_loss)
            tb.save_value('Train Loss', 'd_loss', epoch*num_sample+loader_idx*len(train_loader)+batch_idx, d_loss)  
                
    ## AFTER EACH EPOCH##
    # append discriminator loss and generator loss
    # losses.append((d_loss.item(), g_loss.item()))
    # torch.save(G, 'G.pt')
    # torch.save(D_F, 'FD.pt')
    # # generate and save sample, fake images
    # G.eval() # eval mode for generating samples
    # samples_z = G(fixed_z)
    # samples.append(samples_z)
    # G.train() # back to train mode

# visualization
import numpy as np
import matplotlib.pyplot as plt
import torch

G = torch.load('G.pt')

#1 
dataiter = iter(train_loader1)
images, labels = dataiter.next()
images = images.to(device)
image = images[13]
#2
plt.imshow(image.detach().cpu().permute(1, 2, 0))
G.eval()
image = image.reshape(-1, 3, 64, 64)
img = image*2-1
fake_images_f = G(img, 'f')
fake_images_m = G(img, 'm')
# img = images[8].cpu()
# plt.imshow(img.permute(1, 2, 0))
# D_G = torch.load('GD.pt')
D_G.eval()
D_F.eval()
print(D_G(image))
print(D_G(fake_images_f))
print(D_G(fake_images_m))
print(D_F(fake_images_m))

D_G.eval()
img2 = fake_images_f.detach().cpu()
img2 = img2.reshape(3, 64, 64)
plt.imshow(img2.permute(1, 2, 0))
img2 = img2.reshape(-1, 3, 64, 64).to(device)
print(D_G(img2))

torch.save(G, 'G.pt')
torch.save(D_F, 'FD.pt')