{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqIzsFJQ2Hgr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "541e5d81-ba96-4c3a-92f0-a3cbb7e0cb00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "% cd '/content/drive/My Drive/785_proj/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/785_proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DsbMTEy9VUT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a4b1b38-c847-4bf7-e13b-bcd4963a8aa3"
      },
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1148UkX9gtg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "2786fcc8-ad64-4c25-eff3-dbe602b3d77a"
      },
      "source": [
        "!pip install import-ipynb\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "import import_ipynb\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 32\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize((64,64)),\n",
        "     transforms.ToTensor(),\n",
        "     ])\n",
        "\n",
        "train_data = datasets.ImageFolder(root = 'crop_part1', transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting import-ipynb\n",
            "  Downloading https://files.pythonhosted.org/packages/63/35/495e0021bfdcc924c7cdec4e9fbb87c88dd03b9b9b22419444dc370c8a45/import-ipynb-0.1.3.tar.gz\n",
            "Building wheels for collected packages: import-ipynb\n",
            "  Building wheel for import-ipynb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for import-ipynb: filename=import_ipynb-0.1.3-cp36-none-any.whl size=2975 sha256=a5c6b4c368e897bd26da76eaba957648d1db2102e5b09c3b1e0f3e0318cc55a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/7b/e9/a3a6e496115dffdb4e3085d0ae39ffe8a814eacc44bbf494b5\n",
            "Successfully built import-ipynb\n",
            "Installing collected packages: import-ipynb\n",
            "Successfully installed import-ipynb-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y00gnIZOAp-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from GeneratorUnet import * \n",
        "import DiscriminatorGender\n",
        "from torchvision import models\n",
        "import torch\n",
        "\n",
        "G = UNet(3,3).to(device)\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "mobilenet.classifier = nn.Sequential(\n",
        "    nn.Linear(1280, 2),\n",
        "    nn.Softmax(),\n",
        ")\n",
        "D_F = mobilenet\n",
        "D_G = torch.load('GD.pt')\n",
        "# set gender discriminator to be fixed\n",
        "for param in D_G.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AqMRhjvymMh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "define loss\n",
        "\"\"\"\n",
        "def l2_loss_G(out, input):\n",
        "    criterion = nn.MSEloss()\n",
        "    loss = criterion(out, input)\n",
        "    return loss\n",
        "\n",
        "def gender_D_loss(out, label):\n",
        "    batch_size = out.size(0)\n",
        "    if label == 0:\n",
        "        labels = torch.zeros(batch_size)\n",
        "    if label == 1:\n",
        "        labels = torch.ones(batch_size)\n",
        "    criterion = nn.BCEloss()\n",
        "    return criterion(out, labels)\n",
        "\n",
        "def true_D_loss(out):\n",
        "    batch_size = out.size(0)\n",
        "    labels = torch.ones(batch_size)\n",
        "    criterion = nn.BCELoss()\n",
        "    return criterion(out, labels)\n",
        "\n",
        "def fake_D_loss(out):\n",
        "    batch_size = out.size(0)\n",
        "    labels = torch.ones(batch_size)\n",
        "    criterion = nn.BCELoss()\n",
        "    return criterion(out, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Lr4OhC1mph",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "lr = 0.002\n",
        "d_optimizer = optim.Adam(D_F.parameters(), lr)\n",
        "g_optimizer = optim.Adam(G.parameters(), lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSlS2Pat-FB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "# training hyperparams\n",
        "num_epochs = 100\n",
        "\n",
        "# keep track of loss and generated, \"fake\" samples\n",
        "samples = []\n",
        "losses = []\n",
        "\n",
        "print_every = 10\n",
        "\n",
        "# train the network\n",
        "D_F.train()\n",
        "D_G.train()\n",
        "G.train()\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for batch_i, (real_images, genders) in enumerate(train_loader):\n",
        "                \n",
        "        batch_size = real_images.size(0)\n",
        "\n",
        "        # ============================================\n",
        "        #            TRAIN THE DISCRIMINATOR\n",
        "        # ============================================\n",
        "        \n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        # 1. Train with real images\n",
        "\n",
        "        # Compute the discriminator losses on real images \n",
        "        D_real = D(real_images)\n",
        "        real_loss = true_D_loss(D_real)\n",
        "        \n",
        "        # 2. Train with fake images\n",
        "        \n",
        "        # Generate fake female images\n",
        "        fake_images_f = G(real_images, 0)\n",
        "        fake_images_m = G(real_images, 1)\n",
        "        # Compute the discriminator losses on fake images        \n",
        "        D_fake_f = D(fake_images_f)\n",
        "        d_fake_f_loss = fake_loss(D_fake)\n",
        "        D_fake_m = D(fake_images_m)\n",
        "        d_fake_m_loss = fake_loss(D_fake_m)\n",
        "\n",
        "        # add up loss and perform backprop\n",
        "        d_loss = d_real_loss + d_fake_f_loss + d_fake_m_loss\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        # =========================================\n",
        "        #            TRAIN THE GENERATOR\n",
        "        # =========================================\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        # 1. Train with l2loss\n",
        "        # Generate fake female images\n",
        "        fake_images_f = G(real_images, 0)\n",
        "        fake_images_m = G(real_images, 1)\n",
        "        l2loss_f = l2_loss_G(fake_images_f, real_images)\n",
        "        l2loss_m = l2_loss_G(fake_images_m, real_images)\n",
        "\n",
        "        # using flipped labels!\n",
        "\n",
        "        # 2. Train with gender discriminator\n",
        "        D_G_fake_f = D_G(fake_images_f)\n",
        "        D_G_fake_m = D_G(fake_images_m)\n",
        "\n",
        "        gender_loss_f = gender_d_loss(D_G_fake_f, 0)\n",
        "        gender_loss_m = gender_d_loss(D_G_fake_m, 1)\n",
        "        \n",
        "        # 3. Train with face discriminator\n",
        "        D_F_fake_f = D_F(fake_images_f)\n",
        "        D_F_fake_m = D_F(fake_images_m)\n",
        "\n",
        "        face_loss_f =  true_D_loss(D_F_fake_f)\n",
        "        face_loss_m =  true_D_loss(D_F_fake_m)\n",
        "\n",
        "        # sum all the loss\n",
        "        g_loss = l2loss_f + l2loss_m + gender_loss_f + gender_loss_m + face_loss_f + face_loss_m\n",
        "        # perform backprop\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Print some loss stats\n",
        "        if batch_i % print_every == 0:\n",
        "            # print discriminator and generator loss\n",
        "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
        "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
        "            \n",
        "        ## AFTER EACH EPOCH##\n",
        "        # append discriminator loss and generator loss\n",
        "        losses.append((d_loss.item(), g_loss.item()))\n",
        "        \n",
        "        # generate and save sample, fake images\n",
        "        G.eval() # eval mode for generating samples\n",
        "        samples_z = G(fixed_z)\n",
        "        samples.append(samples_z)\n",
        "        G.train() # back to train mode\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_PvImNP-Q-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "4079a2c9-1e61-44a1-c7cd-e10d63ff5358"
      },
      "source": [
        "epochs = 10\n",
        "train(Gmodel, train_loader)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-847717ad72e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-8e51e804506a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"
          ]
        }
      ]
    }
  ]
}