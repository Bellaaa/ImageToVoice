{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "GenderGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "VqIzsFJQ2Hgr",
    "colab_type": "code",
    "outputId": "e0556357-4fe2-472e-c32b-2ea0140f56ce",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "% cd '/content/drive/My Drive/785_proj/'"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive/785_proj\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8DsbMTEy9VUT",
    "colab_type": "code",
    "outputId": "d7abc08e-eb42-4a9c-f709-a13ad6b0c3f4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 27
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "j1148UkX9gtg",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# !pip install import-ipynb\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import import_ipynb\n",
    "\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 32\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((64,64)),\n",
    "     transforms.ToTensor(),\n",
    "     ])\n",
    "\n",
    "train_data = datasets.ImageFolder(root = 'crop_part1', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "y00gnIZOAp-G",
    "colab_type": "code",
    "outputId": "44d68d84-ac00-4896-8673-451db2b77631",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    }
   },
   "source": [
    "from GeneratorUnet import * \n",
    "from D_G import *\n",
    "from torchvision import models\n",
    "import torch\n",
    "\n",
    "G = UNet(3,3).to(device)\n",
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "mobilenet.classifier = nn.Sequential(\n",
    "    nn.Linear(1280, 2),\n",
    "    nn.Softmax(),\n",
    ")\n",
    "D_F = mobilenet.to(device)\n",
    "D_G = torch.load('GD.pt').to(device)\n",
    "# set gender discriminator to be fixed\n",
    "for param in D_G.parameters():\n",
    "    param.requires_grad = False"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "initilized!\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9AqMRhjvymMh",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "\"\"\"\n",
    "define loss\n",
    "\"\"\"\n",
    "def l2_loss_G(out, input):\n",
    "    criterion = nn.MSELoss()\n",
    "    loss = criterion(out, input)\n",
    "    return loss\n",
    "\n",
    "def gender_D_loss(out, label):\n",
    "    batch_size = out.size(0)\n",
    "    if label == 0:\n",
    "        labels = torch.zeros(batch_size).to(device)\n",
    "    if label == 1:\n",
    "        labels = torch.ones(batch_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(out, labels.long())\n",
    "\n",
    "def true_D_loss(out):\n",
    "    batch_size = out.size(0)\n",
    "    labels = torch.ones(batch_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(out, labels.long())\n",
    "\n",
    "def fake_D_loss(out):\n",
    "    batch_size = out.size(0)\n",
    "    labels = torch.zeros(batch_size).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    return criterion(out, labels.long())"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b-Lr4OhC1mph",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "lr = 0.0002\n",
    "d_optimizer = optim.Adam(D_F.parameters(), lr)\n",
    "g_optimizer = optim.Adam(G.parameters(), lr)"
   ],
   "execution_count": 0,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QSlS2Pat-FB1",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 785
    },
    "outputId": "82f4ec57-79a5-4aec-ef18-e5ad664ce60c"
   },
   "source": [
    "# training\n",
    "# training hyperparams\n",
    "num_epochs = 100\n",
    "\n",
    "# keep track of loss and generated, \"fake\" samples\n",
    "samples = []\n",
    "losses = []\n",
    "\n",
    "print_every = 10\n",
    "\n",
    "# train the network\n",
    "D_F.train()\n",
    "D_G.train()\n",
    "G.train()\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for batch_i, (real_images, genders) in enumerate(train_loader):\n",
    "                \n",
    "        batch_size = real_images.size(0)\n",
    "        real_images, genders = real_images.to(device), genders.to(device)\n",
    "\n",
    "        # ============================================\n",
    "        #            TRAIN THE DISCRIMINATOR\n",
    "        # ============================================\n",
    "        \n",
    "        d_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with real images\n",
    "\n",
    "        # Compute the discriminator losses on real images \n",
    "        D_real = D_F(real_images)\n",
    "        d_real_loss = true_D_loss(D_real)\n",
    "        \n",
    "        # 2. Train with fake images\n",
    "        \n",
    "        # Generate fake female images\n",
    "        fake_images_f = G(real_images, 0)\n",
    "        fake_images_m = G(real_images, 1)\n",
    "\n",
    "        # Compute the discriminator losses on fake images        \n",
    "        D_fake_f = D_F(fake_images_f)\n",
    "        d_fake_f_loss = fake_D_loss(D_fake_f)\n",
    "        \n",
    "        D_fake_m = D_F(fake_images_m)\n",
    "        d_fake_m_loss = fake_D_loss(D_fake_m)\n",
    "        # add up loss and perform backprop\n",
    "        d_loss = d_real_loss + d_fake_f_loss + d_fake_m_loss\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # =========================================\n",
    "        #            TRAIN THE GENERATOR\n",
    "        # =========================================\n",
    "        g_optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Train with l2loss\n",
    "        # Generate fake female images\n",
    "        fake_images_f = G(real_images, 0)\n",
    "        fake_images_m = G(real_images, 1)\n",
    "        l2loss_f = l2_loss_G(fake_images_f, real_images)\n",
    "        l2loss_m = l2_loss_G(fake_images_m, real_images)\n",
    "\n",
    "        # using flipped labels!\n",
    "\n",
    "        # 2. Train with gender discriminator\n",
    "        D_G_fake_f = D_G(fake_images_f)\n",
    "        D_G_fake_m = D_G(fake_images_m)\n",
    "\n",
    "        gender_loss_f = gender_D_loss(D_G_fake_f, 0)\n",
    "        gender_loss_m = gender_D_loss(D_G_fake_m, 1)\n",
    "        \n",
    "        # 3. Train with face discriminator\n",
    "        D_F_fake_f = D_F(fake_images_f)\n",
    "        D_F_fake_m = D_F(fake_images_m)\n",
    "\n",
    "        face_loss_f =  true_D_loss(D_F_fake_f)\n",
    "        face_loss_m =  true_D_loss(D_F_fake_m)\n",
    "\n",
    "        # 4.consistency loss\n",
    "        fake_cycle = G(real_images, genders)\n",
    "        c_loss = l2_loss_G(fake_cycle, real_images)\n",
    "\n",
    "        # sum all the loss\n",
    "        g_loss = l2loss_f + l2loss_m + gender_loss_f + gender_loss_m + face_loss_f + face_loss_m + c_loss\n",
    "        # perform backprop\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        # Print some loss stats\n",
    "        if batch_i % print_every == 0:\n",
    "            # print discriminator and generator loss\n",
    "            print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(\n",
    "                    epoch+1, num_epochs, d_loss.item(), g_loss.item()))\n",
    "            torch.save(G, 'G.pt')\n",
    "            torch.save(D_F, 'FD.pt')\n",
    "            \n",
    "        ## AFTER EACH EPOCH##\n",
    "        # append discriminator loss and generator loss\n",
    "        losses.append((d_loss.item(), g_loss.item()))\n",
    "        \n",
    "        # # generate and save sample, fake images\n",
    "        # G.eval() # eval mode for generating samples\n",
    "        # samples_z = G(fixed_z)\n",
    "        # samples.append(samples_z)\n",
    "        # G.train() # back to train mode\n"
   ],
   "execution_count": 0,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Epoch [    1/  100] | d_loss: 2.1923 | g_loss: 5.4506\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type UNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DoubleConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Down. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Up. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Upsample. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DoubleConv2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type OutConv. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MobileNetV2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvBNReLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU6. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type InvertedResidual. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Softmax. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Epoch [    1/  100] | d_loss: 1.9183 | g_loss: 5.4309\n",
      "Epoch [    1/  100] | d_loss: 1.9109 | g_loss: 5.0453\n",
      "Epoch [    1/  100] | d_loss: 1.8907 | g_loss: 4.6494\n",
      "Epoch [    1/  100] | d_loss: 1.8560 | g_loss: 4.4814\n",
      "Epoch [    1/  100] | d_loss: 1.7968 | g_loss: 4.3389\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HZFsgyNBWOXP",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# visualization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#1 \n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "#2\n",
    "G.eval()\n",
    "fake_images_f = G(images, 0)\n",
    "fake_images_m = G(images, 1)\n",
    "img = images[8].cpu()\n",
    "# plt.imshow(img.permute(1, 2, 0))\n",
    "img2 = fake_images_f[8].detach().cpu()\n",
    "plt.imshow(img2.permute(1, 2, 0))"
   ],
   "execution_count": 0,
   "outputs": []
  }
 ]
}